{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "#### June 29, 2019\n",
    "* Flatiron School (nyc-mhtn-ds-0422019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from private import api_keys\n",
    "from weather import Weather\n",
    "from modeler import Modeler\n",
    "\n",
    "def get_day_time(dt):\n",
    "    if dt.time() > datetime.strptime('00:00', '%H:%M').time():\n",
    "        if dt.time() > datetime.strptime('06:00', '%H:%M').time():\n",
    "            if dt.time() > datetime.strptime('12:00', '%H:%M').time():\n",
    "                if dt.time() > datetime.strptime('18:00', '%H:%M').time():\n",
    "                    return 'evening'\n",
    "                else:\n",
    "                    return 'afternoon'\n",
    "            else:\n",
    "                return 'morning'\n",
    "        else:\n",
    "            return 'night'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Collision Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '../../Datasets/NYPD_Motor_Vehicle_Collisions-June-2019.csv'\n",
    "df = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1766.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dates = df['DATE'].unique()\n",
    "# lat = '40.717743'\n",
    "# long = '-73.72986'\n",
    "\n",
    "# rain = Weather(dates, lat, long)\n",
    "# results = rain.is_rain()\n",
    "df['DATE'].nunique()\n",
    "df['NUMBER OF PERSONS KILLED'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( results, open( \"rain_results.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pickle.load( open( \"rain_results.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### df.info()\n",
    "`RangeIndex: 1520922 entries, 0 to 1520921\n",
    "Data columns (total 34 columns):\n",
    "DATE                             1520922 non-null object\n",
    "TIME                             1520922 non-null object\n",
    "BOROUGH                          1063875 non-null object\n",
    "ZIP CODE                         1063695 non-null object\n",
    "LATITUDE                         1331596 non-null float64\n",
    "LONGITUDE                        1331596 non-null float64\n",
    "LOCATION                         1331596 non-null object\n",
    "ON STREET NAME                   1227003 non-null object\n",
    "CROSS STREET NAME                1026963 non-null object\n",
    "OFF STREET NAME                  201764 non-null object\n",
    "NUMBER OF PERSONS INJURED        1520905 non-null float64\n",
    "NUMBER OF PERSONS KILLED         1520891 non-null float64\n",
    "NUMBER OF PEDESTRIANS INJURED    1520922 non-null int64\n",
    "NUMBER OF PEDESTRIANS KILLED     1520922 non-null int64\n",
    "NUMBER OF CYCLIST INJURED        1520922 non-null int64\n",
    "NUMBER OF CYCLIST KILLED         1520922 non-null int64\n",
    "NUMBER OF MOTORIST INJURED       1520922 non-null int64\n",
    "NUMBER OF MOTORIST KILLED        1520922 non-null int64\n",
    "CONTRIBUTING FACTOR VEHICLE 1    1516958 non-null object\n",
    "CONTRIBUTING FACTOR VEHICLE 2    1318025 non-null object\n",
    "CONTRIBUTING FACTOR VEHICLE 3    98014 non-null object\n",
    "CONTRIBUTING FACTOR VEHICLE 4    20377 non-null object\n",
    "CONTRIBUTING FACTOR VEHICLE 5    5192 non-null object\n",
    "UNIQUE KEY                       1520922 non-null int64\n",
    "VEHICLE TYPE CODE 1              1516039 non-null object\n",
    "VEHICLE TYPE CODE 2              1273660 non-null object\n",
    "VEHICLE TYPE CODE 3              127385 non-null object\n",
    "VEHICLE TYPE CODE 4              48217 non-null object\n",
    "VEHICLE TYPE CODE 5              10305 non-null object\n",
    "Zip Codes                        1316873 non-null float64\n",
    "Borough Boundaries               1322794 non-null float64\n",
    "City Council Districts           1322787 non-null float64\n",
    "Community Districts              1322792 non-null float64\n",
    "Police Precincts                 1322783 non-null float64`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "* Drop NaNs in target column\n",
    "* Convert to ints\n",
    "* Drop suspicious values in the target (Sumchecked against the redundant death columns)\n",
    "* Drop columns with sparse data\n",
    "* Flatten time to one column and convert, then drop the redundants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['NUMBER OF PERSONS KILLED'], inplace=True)\n",
    "df['NUMBER OF PERSONS KILLED'] = df['NUMBER OF PERSONS KILLED'].astype(int)\n",
    "df = df.loc[df['NUMBER OF PERSONS KILLED'] == (df['NUMBER OF CYCLIST KILLED'] + df['NUMBER OF MOTORIST KILLED'] + df['NUMBER OF PEDESTRIANS KILLED'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['UNIQUE KEY', 'NUMBER OF PERSONS INJURED', 'VEHICLE TYPE CODE 3', 'VEHICLE TYPE CODE 4','VEHICLE TYPE CODE 5',\n",
    "                'CONTRIBUTING FACTOR VEHICLE 3', 'CONTRIBUTING FACTOR VEHICLE 4', \n",
    "                'CONTRIBUTING FACTOR VEHICLE 5', 'NUMBER OF PEDESTRIANS INJURED', \n",
    "                'NUMBER OF PEDESTRIANS KILLED', 'NUMBER OF CYCLIST INJURED', \n",
    "                'NUMBER OF CYCLIST KILLED', 'NUMBER OF MOTORIST INJURED', 'NUMBER OF MOTORIST KILLED', 'Zip Codes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(drop_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TIME_DAY'] = df['DATE'] + ' ' + df['TIME']\n",
    "df['TIME_DAY'] = pd.to_datetime(df['TIME_DAY'])\n",
    "df.drop(['DATE', 'TIME'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Engineering\n",
    "#### Create Binary Target (FATAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1519225\n",
       "True        1697\n",
       "Name: FATAL, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['FATAL'] = False\n",
    "df.loc[df['NUMBER OF PERSONS KILLED'] > 0, 'FATAL'] = True\n",
    "df.drop('NUMBER OF PERSONS KILLED', axis=1, inplace=True)\n",
    "df['FATAL'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create days-of-the-week dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekday'] = df['TIME_DAY'].dt.dayofweek\n",
    "day_of_week_dummies = pd.get_dummies(df['weekday'], prefix=\"day\", drop_first=True)\n",
    "df = pd.concat([df, day_of_week_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create time-of-day dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_of_day'] = df['TIME_DAY'].map(lambda x: get_day_time(x) )\n",
    "time_of_day_dummies = pd.get_dummies(df['time_of_day'], prefix=\"tod_\", drop_first=True)\n",
    "df = pd.concat([df, time_of_day_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['weekday','time_of_day', 'TIME_DAY'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['Borough Boundaries', 'City Council Districts', 'Community Districts', 'Police Precincts',\n",
    "               'LATITUDE', 'LONGITUDE', 'LOCATION', 'ON STREET NAME', 'CROSS STREET NAME', 'OFF STREET NAME']\n",
    "\n",
    "df.drop(drop_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporary Cleaning\n",
    "* Removing features just to get the model going"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['ZIP CODE', 'CONTRIBUTING FACTOR VEHICLE 1', 'CONTRIBUTING FACTOR VEHICLE 2', \n",
    "                'VEHICLE TYPE CODE 1', 'VEHICLE TYPE CODE 2' ]\n",
    "df.drop(drop_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['ZIP CODE'] = df['ZIP CODE'].astype(int)\n",
    "# df['ZIP CODE'] = df['ZIP CODE'].astype(str)\n",
    "# zip_dummies = pd.get_dummies(df['ZIP CODE'], prefix=\"zip\", drop_first=True)\n",
    "# df = pd.concat([df, zip_dummies], axis=1)\n",
    "# df.drop('ZIP CODE', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BOROUGH'] = df['BOROUGH'].astype(str)\n",
    "boro_dummies = pd.get_dummies(df['BOROUGH'], prefix=\"boro\", drop_first=True)\n",
    "df = pd.concat([df, boro_dummies], axis=1)\n",
    "df.drop('BOROUGH', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( df, open( \"save.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick save after converting time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle.load( open( \"save.p\", \"rb\" ) )\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'FATAL'\n",
    "\n",
    "fatal_df = df.loc[df[target] == True]\n",
    "fatal_y = fatal_df[target]\n",
    "fatal_X = fatal_df.drop(target, axis=1)\n",
    "\n",
    "non_fatal_df = df.loc[df[target] == False]\n",
    "\n",
    "max_samples = 500\n",
    "downsampled = resample(non_fatal_df,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = max_samples, # match minority n\n",
    "                                random_state = 23) # reproducible results\n",
    "\n",
    "non_fatal_y = downsampled[target]\n",
    "non_fatal_X = downsampled.drop(target, axis=1)\n",
    "\n",
    "fatal_X_train, fatal_X_test, fatal_y_train, fatal_y_test = train_test_split(fatal_X, fatal_y, test_size=0.25, random_state=23)\n",
    "non_fatal_X_train, non_fatal_X_test, non_fatal_y_train, non_fatal_y_test = train_test_split(non_fatal_X, non_fatal_y, test_size=0.25, random_state=23)\n",
    "\n",
    "X_train = pd.concat([fatal_X_train,non_fatal_X_train])\n",
    "X_test = pd.concat([fatal_X_test,non_fatal_X_test])\n",
    "y_train = pd.concat([fatal_y_train,non_fatal_y_train])\n",
    "y_test = pd.concat([fatal_y_test,non_fatal_y_test])\n",
    "\n",
    "features = list(df.columns)\n",
    "features.pop(features.index(target))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = pd.DataFrame(data=scaler.transform(X_train), columns=features)\n",
    "X_test = pd.DataFrame(data=scaler.transform(X_test), columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline  \n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "sns.countplot(y_train, alpha =.80, palette= ['grey','lightgreen'])\n",
    "plt.title('Fatalities')\n",
    "plt.ylabel('Collisions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''LogisticRegression(C=1000000000.0, class_weight=None, dual=False,\n",
    "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "          multi_class='ovr', penalty='l2', random_state=None,\n",
    "          solver='liblinear', tol=0.0001, verbose=0)'''\n",
    "\n",
    "logreg = LogisticRegression(C=100, solver='liblinear')\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_class))\n",
    "\n",
    "result = {'type':'Logistic Regression','accuracy':accuracy_score(y_test, y_pred_class), 'coefficients':logreg.coef_}\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_scores=[]\n",
    "k_range = list(range(9, 22,2))\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_class= knn.predict(X_test)\n",
    "    k_scores.append(f1_score(y_pred_class, y_test))\n",
    "    \n",
    "plt.figure(figsize=(12, 6))  \n",
    "plt.plot(k_range, k_scores, color='red', linestyle='dashed', marker='o',  \n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Accuracy score by K Value')  \n",
    "plt.xlabel('K Value')  \n",
    "plt.ylabel('Accuracy Score') \n",
    "plt.show()\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_class = knn.predict(X_test)\n",
    "print('Accuracy:' + str(accuracy_score(y_test, y_pred_class)))\n",
    "print('F1: ' + str(f1_score(y_test, y_pred_class)))\n",
    "\n",
    "result = {'type':'KNN','accuracy':accuracy_score(y_test, y_pred_class), 'f1':f1_score(y_test, y_pred_class)}\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "            oob_score=False, random_state=23, verbose=0, warm_start=False)'''\n",
    "\n",
    "f1_scores=[]\n",
    "n_range = list(range(10,100,10))\n",
    "for n in n_range:\n",
    "    rfc = RandomForestClassifier(random_state = 23, n_estimators=n)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    rfc_pred = rfc.predict(X_test)\n",
    "    f1_scores.append(f1_score(y_pred_class, y_test))\n",
    "    \n",
    "plt.figure(figsize=(12, 6))  \n",
    "plt.plot(n_range, f1_scores, color='red', linestyle='dashed', marker='o',  \n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('F1 score by N Value')  \n",
    "plt.xlabel('N Value')  \n",
    "plt.ylabel('F1 Score') \n",
    "plt.show()\n",
    "\n",
    "rfc = RandomForestClassifier(random_state = 23, n_estimators=100)\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "print('Test Accuracy score: ', accuracy_score(y_test, rfc_pred))\n",
    "print('Test F1 score: ', f1_score(y_test, rfc_pred))\n",
    "\n",
    "result = {'type':'Random Forest','accuracy':accuracy_score(y_test, y_pred_class), 'f1':f1_score(y_test, y_pred_class)}\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores=[]\n",
    "n_range = list(range(1,8))\n",
    "for n in n_range:\n",
    "    clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=n)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred_class= clf.predict(X_test)\n",
    "    f1_scores.append(f1_score(y_pred_class, y_test))\n",
    "    \n",
    "plt.figure(figsize=(12, 6))  \n",
    "plt.plot(n_range, f1_scores, color='red', linestyle='dashed', marker='o',  \n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Accuracy score by N Value')  \n",
    "plt.xlabel('N Value')  \n",
    "plt.ylabel('F1 Score') \n",
    "plt.show()\n",
    "\n",
    "f1_scores=[]\n",
    "n_range = list(range(1,8))\n",
    "for n in n_range:\n",
    "    clf = DecisionTreeClassifier(criterion=\"gini\", max_depth=n)\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred_class= clf.predict(X_test)\n",
    "    f1_scores.append(f1_score(y_pred_class, y_test))\n",
    "    \n",
    "plt.figure(figsize=(12, 6))  \n",
    "plt.plot(n_range, f1_scores, color='red', linestyle='dashed', marker='o',  \n",
    "         markerfacecolor='blue', markersize=10)\n",
    "plt.title('Accuracy score by N Value')  \n",
    "plt.xlabel('N Value')  \n",
    "plt.ylabel('F1 Score') \n",
    "plt.show()\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=2)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print('Test Accuracy score: ', accuracy_score(y_test, y_pred_test))\n",
    "print('Test F1 score: ', f1_score(y_test, y_pred_test))\n",
    "\n",
    "result = {'type':'Desision Tree','accuracy':accuracy_score(y_test, y_pred_class), 'f1':f1_score(y_test, y_pred_class)}\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''GridSearchCV(cv=5, error_score='raise-deprecating',\n",
    "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "            oob_score=False, random_state=23, verbose=0, warm_start=False),\n",
    "       fit_params=None, iid='warn', n_jobs=-1,\n",
    "       param_grid={'n_estimators': [100, 200, 300, 400]},\n",
    "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
    "       scoring=None, verbose=0)'''\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [100,200,300,400]\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(cv=5, error_score='raise-deprecating',\n",
    "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "            oob_score=False, random_state=23, verbose=0, warm_start=False), param_grid=param_grid)\n",
    "CV_rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CV_rfc.best_score_)\n",
    "#predict on the test set\n",
    "print(CV_rfc.best_estimator_)\n",
    "\n",
    "y_pred_test = CV_rfc.best_estimator_.predict(X_test)\n",
    "\n",
    "# checking accuracy\n",
    "print('Test Accuracy score: ', accuracy_score(y_test, y_pred_test))\n",
    "print('Test F1 score: ', f1_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
    "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
    "       n_estimators=100, n_jobs=1, nthread=None,\n",
    "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
    "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
    "       subsample=1, verbosity=1)'''\n",
    "\n",
    "xg_clf = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                           colsample_bytree = 0.3, \n",
    "                           learning_rate = 0.1,\n",
    "                           max_depth = 2, \n",
    "                           alpha = 1, \n",
    "                           n_estimators = 100)\n",
    "\n",
    "xg_clf.fit(X_train,y_train)\n",
    "y_pred_test = xg_clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print('Test Accuracy score: ', accuracy_score(y_test, y_pred_test))\n",
    "print('Test F1 score: ', f1_score(y_test, y_pred_test))\n",
    "\n",
    "result = {'type':'XGBoost','accuracy':accuracy_score(y_test, y_pred_class), 'f1':f1_score(y_test, y_pred_class)}\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
